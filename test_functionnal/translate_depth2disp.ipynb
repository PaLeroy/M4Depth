{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_put_test_1_former (1, 24, 24, 1) (1, 24, 24, 1)\n",
      "---\n",
      "disp_test_1 (1, 24, 24, 1)\n",
      "out_put_test_1 (1, 24, 24, 1) (1, 24, 24, 1)\n",
      "tf.Tensor(\n",
      "[[ 0.0046895 ]\n",
      " [-0.00181194]\n",
      " [-0.00105495]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.0046895 ]\n",
      " [-0.00181194]\n",
      " [-0.00105495]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "out_put_test_1_former (50, 24, 24, 1) (50, 24, 24, 1)\n",
      "---\n",
      "disp_test_1 (50, 24, 24, 1)\n",
      "out_put_test_1 (50, 24, 24, 1) (50, 24, 24, 1)\n",
      "tf.Tensor(\n",
      "[[4.4485908 ]\n",
      " [1.798833  ]\n",
      " [0.51340675]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4.4485908 ]\n",
      " [1.798833  ]\n",
      " [0.51340675]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.depth_operations_functionnal import get_coords_2d, get_rot_mat, \\\n",
    "    repeat_const\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks, float32\n",
    "from keras import backend as K\n",
    "\n",
    "@tf.function\n",
    "def depth2disp_former(depth, rot, trans, camera):\n",
    "    \"\"\" Converts a depth map into a disparity map according to given camera motion and specifications \"\"\"\n",
    "\n",
    "    with tf.compat.v1.name_scope(\"depth2disp\"):\n",
    "        b, h, w = depth.get_shape().as_list()[0:3]\n",
    "\n",
    "        coords2d, _ = get_coords_2d(depth, camera)\n",
    "\n",
    "        depth = tf.reshape(depth, [b, h * w, 1, 1])\n",
    "        coords2d = tf.reshape(coords2d, [b, h * w, 3, 1])\n",
    "        rot_mat = tf.expand_dims(get_rot_mat(rot), axis=1)\n",
    "        t = tf.reshape(trans, [b, 1, 3, 1])\n",
    "        f_vec = tf.reshape(tf.concat([camera[\"f\"], tf.ones([b, 1])], axis=1),\n",
    "                           [b, 1, 3, 1])\n",
    "\n",
    "        rot_coords = rot_mat @ coords2d\n",
    "        alpha = rot_coords[:, :, -1:, :]\n",
    "        proj_coords = rot_coords * f_vec / alpha\n",
    "        scaled_t = t * f_vec\n",
    "\n",
    "        delta_x = scaled_t[:, :, 0, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                                :, 0, 0]\n",
    "        delta_y = scaled_t[:, :, 1, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                                :, 1, 0]\n",
    "\n",
    "        sqrt_value = tf.reshape(tf.sqrt(delta_x ** 2 + delta_y ** 2),\n",
    "                                [b, h * w, 1, 1])\n",
    "\n",
    "        disp = sqrt_value / (depth * alpha + scaled_t[:, :, -1:, :])\n",
    "\n",
    "        return tf.reshape(disp, [b, h, w, 1])\n",
    "\n",
    "@tf.function\n",
    "def depth2disp(depth, rot, trans, camera):\n",
    "    \"\"\" Converts a depth map into a disparity map according to given camera motion and specifications \"\"\"\n",
    "\n",
    "    b, h, w = depth.get_shape().as_list()[0:3]\n",
    "\n",
    "    coords2d, _ = get_coords_2d(depth, camera)\n",
    "\n",
    "    depth = ks.layers.Reshape((h * w, 1, 1,), )(depth)\n",
    "    coords2d = ks.layers.Reshape((h * w, 3, 1,), )(coords2d)\n",
    "\n",
    "    rot_mat = get_rot_mat(rot)\n",
    "    rot_mat = ks.layers.Reshape((1, rot_mat.shape[1], rot_mat.shape[2],), )(rot_mat)\n",
    "    t = ks.layers.Reshape((1, 3, 1,), )(trans)\n",
    "\n",
    "    myconst = tf.convert_to_tensor(np.ones((1, 1)).astype('float32'))\n",
    "    ones_ = tf.keras.layers.Lambda(lambda x: repeat_const(x, myconst))(camera[\"f\"])\n",
    "    f_vec = ks.layers.Concatenate(axis=1)([camera[\"f\"], ones_])\n",
    "    f_vec =  ks.layers.Reshape((1, 3, 1,),)(f_vec)\n",
    "\n",
    "    rot_coords = rot_mat @ coords2d\n",
    "    alpha = rot_coords[:, :, -1:, :]\n",
    "    proj_coords = rot_coords * f_vec / alpha\n",
    "    scaled_t = t * f_vec\n",
    "\n",
    "    delta_x = scaled_t[:, :, 0, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                            :, 0, 0]\n",
    "    delta_y = scaled_t[:, :, 1, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                            :, 1, 0]\n",
    "    sqrt_value = tf.sqrt(delta_x ** 2 + delta_y ** 2)\n",
    "    sqrt_value = ks.layers.Reshape((h * w, 1, 1,), ) (sqrt_value)\n",
    "\n",
    "    disp = sqrt_value / (depth * alpha + scaled_t[:, :, -1:, :])\n",
    "\n",
    "    disp = ks.layers.Reshape((h, w, 1,), ) (disp)\n",
    "\n",
    "    return disp\n",
    "\n",
    "\n",
    "disp = ks.Input(shape=(24, 24, 1,), dtype=float32)  # data image\n",
    "camera = {\"f\": ks.Input(shape=(2,), dtype=float32),\n",
    "          \"c\": ks.Input(shape=(2,), dtype=float32)}\n",
    "\n",
    "rot_input = ks.Input(shape=(4), dtype=float32,\n",
    "                     name=\"rot_input\")  # data camera displacement\n",
    "trans_input = ks.Input(shape=(3), dtype=float32,\n",
    "                       name=\"trans_input\")  # data camera displacement\n",
    "# output: TensorShape([1, 48, 48, 1])\n",
    "\n",
    "b=1\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "\n",
    "out_put_test_1_former = depth2disp_former(disp_test_1, rot_test_1, trans_test_1, camera_test_1)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former.shape, disp_test_1.shape)\n",
    "print(\"---\")\n",
    "\n",
    "depth_curr_l_function = lambda x: depth2disp(x[0], x[1], x[2], x[3])\n",
    "depth_curr_l = ks.layers.Lambda(depth_curr_l_function)((disp,rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[disp, camera, rot_input, trans_input],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "out_put_test_1 = model_full((disp_test_1, camera_test_1, rot_test_1, trans_test_1))\n",
    "\n",
    "print(\"disp_test_1\", disp_test_1.shape)\n",
    "print(\"out_put_test_1\", out_put_test_1.shape, disp_test_1.shape)\n",
    "\n",
    "print(out_put_test_1[0][0][0:3])\n",
    "print(out_put_test_1_former[0][0][0:3])\n",
    "print()\n",
    "\n",
    "\n",
    "b=50\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "\n",
    "out_put_test_1_former = depth2disp_former(disp_test_1, rot_test_1, trans_test_1, camera_test_1)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former.shape, disp_test_1.shape)\n",
    "print(\"---\")\n",
    "\n",
    "depth_curr_l_function = lambda x: depth2disp(x[0], x[1], x[2], x[3])\n",
    "depth_curr_l = ks.layers.Lambda(depth_curr_l_function)((disp,rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[disp, camera, rot_input, trans_input],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "out_put_test_1 = model_full((disp_test_1, camera_test_1, rot_test_1, trans_test_1))\n",
    "\n",
    "print(\"disp_test_1\", disp_test_1.shape)\n",
    "print(\"out_put_test_1\", out_put_test_1.shape, disp_test_1.shape)\n",
    "\n",
    "print(out_put_test_1[0][0][0:3])\n",
    "print(out_put_test_1_former[0][0][0:3])\n",
    "print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}