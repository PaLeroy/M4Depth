{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_put_test_1_former (1, 24, 24, 1) (1, 24, 24, 1)\n",
      "---\n",
      "(None, 576)\n",
      "(1, 576)\n",
      "disp_test_1 (1, 24, 24, 1)\n",
      "out_put_test_1 (1, 24, 24, 1) (1, 24, 24, 1)\n",
      "tf.Tensor(\n",
      "[[-10.133652 ]\n",
      " [ -0.7192081]\n",
      " [ -0.3633991]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-10.133652 ]\n",
      " [ -0.7192081]\n",
      " [ -0.3633991]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "out_put_test_1_former (50, 24, 24, 1) (50, 24, 24, 1)\n",
      "---\n",
      "(None, 576)\n",
      "(50, 576)\n",
      "disp_test_1 (50, 24, 24, 1)\n",
      "out_put_test_1 (50, 24, 24, 1) (50, 24, 24, 1)\n",
      "tf.Tensor(\n",
      "[[0.5582957 ]\n",
      " [0.32063982]\n",
      " [0.9174991 ]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.55829567]\n",
      " [0.3206398 ]\n",
      " [0.9174992 ]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.depth_operations_functionnal import get_coords_2d, get_rot_mat, \\\n",
    "    repeat_const\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks, float32\n",
    "from keras import backend as K\n",
    "\n",
    "@tf.function\n",
    "def disp2depth_former(disp, rot, trans, camera):\n",
    "    \"\"\" Converts a disparity map into a depth map according to given camera motion and specifications \"\"\"\n",
    "\n",
    "    with tf.compat.v1.name_scope(\"disp2depth\"):\n",
    "        b, h, w = disp.shape[0:3]\n",
    "\n",
    "        coords2d, _ = get_coords_2d(disp, camera)\n",
    "        disp = tf.maximum(tf.reshape(disp, [b, h * w, 1, 1]), 1e-5)\n",
    "        coords2d = tf.reshape(coords2d, [b, h * w, 3, 1])\n",
    "        rot_mat=get_rot_mat(rot)\n",
    "        rot_mat = tf.expand_dims(rot_mat, axis=1)\n",
    "        t = tf.reshape(trans, [b, 1, 3, 1])\n",
    "        f_vec = tf.reshape(tf.concat([camera[\"f\"], tf.ones([b, 1])], axis=1),\n",
    "                           [b, 1, 3, 1])\n",
    "        rot_coords = rot_mat @ coords2d\n",
    "        alpha = rot_coords[:, :, -1:, :]\n",
    "        proj_coords = rot_coords * f_vec / alpha\n",
    "        scaled_t = t * f_vec\n",
    "\n",
    "        delta_x = scaled_t[:, :, 0, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                                :, 0, 0]\n",
    "        delta_y = scaled_t[:, :, 1, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                                :, 1, 0]\n",
    "\n",
    "        sqrt_value = tf.reshape(tf.sqrt(delta_x ** 2 + delta_y ** 2),\n",
    "                                [b, h * w, 1, 1])\n",
    "\n",
    "        depth = (sqrt_value / disp - scaled_t[:, :, -1:, :]) / alpha\n",
    "\n",
    "        to_ret= tf.reshape(depth, [b, h, w, 1])\n",
    "        return to_ret\n",
    "\n",
    "def disp2depth(disp, rot, trans, camera):\n",
    "    \"\"\" Converts a disparity map into a depth map according to given camera motion and specifications \"\"\"\n",
    "    b, h, w = disp.shape[0:3]\n",
    "    coords2d, _ = get_coords_2d(disp, camera)\n",
    "    disp = ks.layers.Reshape((h * w, 1, 1,), )(disp)\n",
    "\n",
    "    max_function = lambda x : tf.maximum(x, 1e-5)\n",
    "    disp = ks.layers.Lambda(max_function)(disp)\n",
    "\n",
    "    coords2d = ks.layers.Reshape((h * w, 3, 1,), )(coords2d)\n",
    "    rot_mat = get_rot_mat(rot)\n",
    "    # rot_mat = tf.expand_dims(rot_mat, axis=1)\n",
    "    # expand_function = lambda x : tf.expand_dims(x, axis=1)\n",
    "    # rot_mat = ks.layers.Lambda(expand_function)(rot_mat)\n",
    "    rot_mat = ks.layers.Reshape((1, rot_mat.shape[1], rot_mat.shape[2],), )(rot_mat)\n",
    "\n",
    "    t = ks.layers.Reshape((1, 3, 1,), )(trans)\n",
    "    myconst = tf.convert_to_tensor(np.ones((1, 1)).astype('float32'))\n",
    "    ones_ = tf.keras.layers.Lambda(lambda x: repeat_const(x, myconst))(camera[\"f\"])\n",
    "    f_vec = ks.layers.Concatenate(axis=1)([camera[\"f\"], ones_])\n",
    "    f_vec =  ks.layers.Reshape((1, 3, 1,),)(f_vec)\n",
    "\n",
    "    rot_coords = rot_mat @ coords2d\n",
    "    alpha = rot_coords[:, :, -1:, :]\n",
    "    proj_coords = rot_coords * f_vec / alpha\n",
    "    scaled_t = t * f_vec\n",
    "\n",
    "    delta_x = scaled_t[:, :, 0, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                            :, 0, 0]\n",
    "    delta_y = scaled_t[:, :, 1, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                            :, 1, 0]\n",
    "\n",
    "    sqrt_value = tf.sqrt(delta_x ** 2 + delta_y ** 2)\n",
    "    sqrt_value = ks.layers.Reshape((h * w, 1, 1,), )(sqrt_value)\n",
    "\n",
    "\n",
    "    depth = (sqrt_value / disp - scaled_t[:, :, -1:, :]) / alpha\n",
    "    depth = ks.layers.Reshape((h, w, 1,), )(depth)\n",
    "\n",
    "    return depth\n",
    "\n",
    "\n",
    "disp = ks.Input(shape=(24, 24, 1,), dtype=float32)  # data image\n",
    "camera = {\"f\": ks.Input(shape=(2,), dtype=float32),\n",
    "          \"c\": ks.Input(shape=(2,), dtype=float32)}\n",
    "\n",
    "rot_input = ks.Input(shape=(4), dtype=float32,\n",
    "                     name=\"rot_input\")  # data camera displacement\n",
    "trans_input = ks.Input(shape=(3), dtype=float32,\n",
    "                       name=\"trans_input\")  # data camera displacement\n",
    "# output: TensorShape([1, 48, 48, 1])\n",
    "\n",
    "b=1\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "\n",
    "out_put_test_1_former = disp2depth_former(disp_test_1, rot_test_1, trans_test_1, camera_test_1)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former.shape, disp_test_1.shape)\n",
    "print(\"---\")\n",
    "\n",
    "depth_curr_l_function = lambda x: disp2depth(x[0], x[1], x[2], x[3])\n",
    "depth_curr_l = ks.layers.Lambda(depth_curr_l_function)((disp,rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[disp, camera, rot_input, trans_input],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "out_put_test_1 = model_full((disp_test_1, camera_test_1, rot_test_1, trans_test_1))\n",
    "\n",
    "print(\"disp_test_1\", disp_test_1.shape)\n",
    "print(\"out_put_test_1\", out_put_test_1.shape, disp_test_1.shape)\n",
    "\n",
    "print(out_put_test_1[0][0][0:3])\n",
    "print(out_put_test_1_former[0][0][0:3])\n",
    "print()\n",
    "\n",
    "\n",
    "b=50\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "\n",
    "out_put_test_1_former = disp2depth_former(disp_test_1, rot_test_1, trans_test_1, camera_test_1)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former.shape, disp_test_1.shape)\n",
    "print(\"---\")\n",
    "\n",
    "depth_curr_l_function = lambda x: disp2depth(x[0], x[1], x[2], x[3])\n",
    "depth_curr_l = ks.layers.Lambda(depth_curr_l_function)((disp,rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[disp, camera, rot_input, trans_input],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "out_put_test_1 = model_full((disp_test_1, camera_test_1, rot_test_1, trans_test_1))\n",
    "\n",
    "print(\"disp_test_1\", disp_test_1.shape)\n",
    "print(\"out_put_test_1\", out_put_test_1.shape, disp_test_1.shape)\n",
    "\n",
    "print(out_put_test_1[0][0][0:3])\n",
    "print(out_put_test_1_former[0][0][0:3])\n",
    "print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}