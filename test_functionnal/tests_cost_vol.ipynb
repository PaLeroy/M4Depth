{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 18:17:37.032585: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 2)\n",
      "(4, 96, 96, 98)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "c1=tf.random.uniform((4, 96, 96, 32))\n",
    "max_offset=7\n",
    "dilation_rate=1\n",
    "search_range=3\n",
    "nbre_cuts=2\n",
    "\n",
    "c1 = tf.cast(c1, tf.float16)\n",
    "\n",
    "strided_search_range = search_range * dilation_rate\n",
    "padded_lvl = tf.pad(c1, [[0, 0],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [0, 0]])\n",
    "_, h, w, _ = c1.get_shape().as_list()\n",
    "\n",
    "c1_nchw = tf.transpose(c1, perm=[0, 3, 1, 2])\n",
    "pl_nchw = tf.transpose(padded_lvl, perm=[0, 3, 1, 2])\n",
    "\n",
    "c1_nchw = tf.stack(\n",
    "    tf.split(c1_nchw, num_or_size_splits=nbre_cuts, axis=1), axis=4)\n",
    "pl_nchw = tf.stack(\n",
    "    tf.split(pl_nchw, num_or_size_splits=nbre_cuts, axis=1), axis=4)\n",
    "cost_vol = []\n",
    "for y in range(0, max_offset):\n",
    "    for x in range(0, max_offset):\n",
    "        slice = tf.slice(pl_nchw,\n",
    "                         [0, 0, y * dilation_rate, x * dilation_rate,0],\n",
    "                         [-1, -1, h, w, -1])\n",
    "\n",
    "        cost = tf.reduce_mean(c1_nchw * slice, axis=1)\n",
    "        print(cost.shape)\n",
    "        cost_vol.append(cost)\n",
    "cost_vol = tf.concat(cost_vol, axis=3)\n",
    "print(cost_vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 96, 96, 32)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 16, 2)\n",
      "(4, 96, 96, 98)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "c1=tf.random.uniform((4, 96, 96, 32))\n",
    "max_offset=7\n",
    "dilation_rate=1\n",
    "search_range=3\n",
    "nbre_cuts=2\n",
    "\n",
    "c1 = tf.cast(c1, tf.float16)\n",
    "print(c1.shape)\n",
    "strided_search_range = search_range * dilation_rate\n",
    "padded_lvl = tf.pad(c1, [[0, 0],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [0, 0]])\n",
    "_, h, w, _ = c1.get_shape().as_list()\n",
    "c1_nchw = c1 #tf.transpose(c1, perm=[0, 3, 1, 2])\n",
    "pl_nchw = padded_lvl #tf.transpose(padded_lvl, perm=[0, 3, 1, 2])\n",
    "\n",
    "cost_vol = []\n",
    "for y in range(0, max_offset):\n",
    "    for x in range(0, max_offset):\n",
    "        #print([0, y * dilation_rate, x * dilation_rate,0])\n",
    "        slice = tf.slice(pl_nchw,\n",
    "                         [0, y * dilation_rate, x * dilation_rate,0],\n",
    "                         [-1, h, w, -1])\n",
    "        # print(slice.shape)\n",
    "        # aze = c1_nchw * slice\n",
    "        aze = tf.stack(\n",
    "                tf.split(c1_nchw * slice, num_or_size_splits=nbre_cuts, axis=3), axis=4)\n",
    "        print(aze.shape)\n",
    "        cost = tf.reduce_mean(aze, axis=-2)\n",
    "        cost_vol.append(cost)\n",
    "cost_vol = tf.concat(cost_vol, axis=3)\n",
    "print(cost_vol.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 96, 96, 49, 32)\n",
      "(4, 96, 96, 49, 16, 2)\n",
      "tf.Tensor([0.1815  0.02715], shape=(2,), dtype=float16)\n",
      "(4, 96, 96, 49, 2)\n",
      "(4, 96, 96, 98)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "c1=tf.random.uniform((4, 96, 96, 32))\n",
    "max_offset=7\n",
    "dilation_rate=1\n",
    "search_range=3\n",
    "nbre_cuts=2\n",
    "\n",
    "c1 = tf.cast(c1, tf.float16)\n",
    "\n",
    "strided_search_range = search_range * dilation_rate\n",
    "padded_lvl = tf.pad(c1, [[0, 0],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [0, 0]])\n",
    "_, h, w, _ = c1.get_shape().as_list()\n",
    "c1_nchw = c1 #tf.transpose(c1, perm=[0, 3, 1, 2])\n",
    "pl_nchw = padded_lvl #tf.transpose(padded_lvl, perm=[0, 3, 1, 2])\n",
    "\n",
    "list_all= []\n",
    "cost_vol = []\n",
    "for y in range(0, max_offset):\n",
    "    for x in range(0, max_offset):\n",
    "        slice = tf.slice(pl_nchw,\n",
    "                         [0, y * dilation_rate, x * dilation_rate,0],\n",
    "                         [-1, h, w, -1])\n",
    "        list_all.append(c1_nchw*slice)\n",
    "\n",
    "list_all=tf.stack(list_all, axis=-2)\n",
    "print(list_all.shape)\n",
    "aze = tf.stack(tf.split(list_all, num_or_size_splits=nbre_cuts, axis=-1), axis=-1)\n",
    "print(aze.shape)\n",
    "print(aze[0, 45, 45, 0, 0, :])\n",
    "cost = tf.reduce_mean(aze, axis=-2)\n",
    "print(cost.shape)\n",
    "cost_vol = tf.reshape(cost, cost.shape[0:3] + [cost.shape[3]*cost.shape[4]])\n",
    "print(cost_vol.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 7, 96, 96, 32)\n",
      "(4, 96, 96, 98)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "c1=tf.random.uniform((4, 96, 96, 32))\n",
    "max_offset=7\n",
    "dilation_rate=1\n",
    "search_range=3\n",
    "nbre_cuts=2\n",
    "\n",
    "c1 = tf.cast(c1, tf.float16)\n",
    "\n",
    "strided_search_range = search_range * dilation_rate\n",
    "padded_lvl = tf.pad(c1, [[0, 0],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [0, 0]])\n",
    "_, h, w, _ = c1.get_shape().as_list()\n",
    "c1_nchw = c1 #tf.transpose(c1, perm=[0, 3, 1, 2])\n",
    "pl_nchw = padded_lvl #tf.transpose(padded_lvl, perm=[0, 3, 1, 2])\n",
    "\n",
    "list_all2=tf.image.extract_patches(pl_nchw,\n",
    "                                   sizes=[1, h, w, 1],\n",
    "                                   strides=[1, dilation_rate, dilation_rate,1],\n",
    "                                   rates=[1,1,1,1],\n",
    "                                   padding=\"VALID\")\n",
    "list_all2=tf.reshape(list_all2, list_all2.shape[0:3]+c1.shape[1:4])\n",
    "c1_repeat = tf.expand_dims(c1,axis=1)\n",
    "c1_repeat = tf.expand_dims(c1_repeat,axis=1)\n",
    "c1_repeat = tf.tile(c1_repeat, [1,list_all2.shape[1], list_all2.shape[2],1, 1, 1])\n",
    "list_all2 = c1_repeat*list_all2\n",
    "print(list_all2.shape)\n",
    "split_stack = tf.stack(tf.split(list_all2, num_or_size_splits=nbre_cuts, axis=-1), axis=-1)\n",
    "cost = tf.reduce_mean(split_stack, axis=-2)\n",
    "cost = tf.transpose(cost, perm=[0, 3, 4, 1, 2, 5])\n",
    "cost_vol = tf.reshape(cost, cost.shape[0:1] + cost.shape[1:3] + [cost.shape[3]*cost.shape[4]*cost.shape[5]])\n",
    "print(cost_vol.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct list (4, 7, 7, 96, 96, 32)\n",
      "correct: (4, 7, 7, 96, 96, 32)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "(4, 96, 96, 98)\n",
      "(4, 96, 96, 98)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "c1=tf.random.uniform((4, 96, 96, 32))\n",
    "max_offset=7\n",
    "dilation_rate=1\n",
    "search_range=3\n",
    "nbre_cuts=2\n",
    "\n",
    "c1 = tf.cast(c1, tf.float16)\n",
    "\n",
    "strided_search_range = search_range * dilation_rate\n",
    "padded_lvl = tf.pad(c1, [[0, 0],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [0, 0]])\n",
    "_, h, w, c = c1.get_shape().as_list()\n",
    "c1_nchw = c1 #tf.transpose(c1, perm=[0, 3, 1, 2])\n",
    "pl_nchw = padded_lvl #tf.transpose(padded_lvl, perm=[0, 3, 1, 2])\n",
    "_, h_pad, w_pad, _ = pl_nchw.shape\n",
    "\n",
    "list_all2=tf.image.extract_patches(pl_nchw,\n",
    "                                   sizes=[1, h, w, 1],\n",
    "                                   strides=[1, dilation_rate, dilation_rate,1],\n",
    "                                   rates=[1,1,1,1],\n",
    "                                   padding=\"VALID\")\n",
    "\n",
    "\n",
    "list_all2=tf.reshape(list_all2, list_all2.shape[0:3]+c1.shape[1:4])\n",
    "print(\"correct list\", list_all2.shape)\n",
    "\n",
    "def patches_indices_meshgrid(image, patch_h, patch_w):\n",
    "    b, h, w, c = image.shape\n",
    "    indices=[list(tf.convert_to_tensor(tf.meshgrid(tf.range(b), tf.range(i, i + patch_h), tf.range(j, j + patch_w), tf.range(c)))) for i in range(0, h-patch_h+1) for j in range(0, w-patch_w+1)]\n",
    "    indices=tf.convert_to_tensor(indices)\n",
    "    # The indices are correct but we need to transpose to have the same order as extract_patches\n",
    "    indices = tf.transpose(indices, [0, 3, 2, 4, 5, 1])\n",
    "    indices = tf.reshape(indices, [indices.shape[0], -1, indices.shape[-1]])\n",
    "    return indices\n",
    "p_h=h\n",
    "p_w=w\n",
    "\n",
    "indices = patches_indices_meshgrid(pl_nchw, p_h, p_w)\n",
    "patches = tf.gather_nd(pl_nchw, indices, batch_dims=0)\n",
    "patches = tf.reshape(patches, [search_range*2+1, search_range*2+1, -1, h, w, c])\n",
    "patches = tf.transpose(patches, perm=[2, 0, 1, 3, 4, 5])\n",
    "print(\"correct:\",list_all2.shape)\n",
    "print(tf.reduce_all(tf.math.equal(list_all2, patches)))\n",
    "\n",
    "c1_repeat = tf.expand_dims(c1,axis=1)\n",
    "c1_repeat = tf.expand_dims(c1_repeat,axis=1)\n",
    "c1_repeat = tf.tile(c1_repeat, [1,list_all2.shape[1], list_all2.shape[2],1, 1, 1])\n",
    "\n",
    "list_all2 = c1_repeat*list_all2\n",
    "split_stack = tf.stack(tf.split(list_all2, num_or_size_splits=nbre_cuts, axis=-1), axis=-1)\n",
    "cost = tf.reduce_mean(split_stack, axis=-2)\n",
    "cost = tf.transpose(cost, perm=[0, 3, 4, 1, 2, 5])\n",
    "cost_vol = tf.reshape(cost, cost.shape[0:1] + cost.shape[1:3] + [cost.shape[3]*cost.shape[4]*cost.shape[5]])\n",
    "print(cost_vol.shape)\n",
    "\n",
    "patches = c1_repeat*patches\n",
    "split_stack = tf.stack(tf.split(patches, num_or_size_splits=nbre_cuts, axis=-1), axis=-1)\n",
    "cost = tf.reduce_mean(split_stack, axis=-2)\n",
    "cost = tf.transpose(cost, perm=[0, 3, 4, 1, 2, 5])\n",
    "cost_vol2 = tf.reshape(cost, cost.shape[0:1] + cost.shape[1:3] + [cost.shape[3]*cost.shape[4]*cost.shape[5]])\n",
    "print(cost_vol2.shape)\n",
    "print(tf.reduce_all(tf.math.equal(cost_vol2, cost_vol)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 15:06:16.165689: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 96, 96, 98)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "c1=tf.random.uniform((4, 96, 96, 32))\n",
    "max_offset=7\n",
    "dilation_rate=1\n",
    "search_range=3\n",
    "nbre_cuts=2\n",
    "\n",
    "c1 = tf.cast(c1, tf.float16)\n",
    "\n",
    "strided_search_range = search_range * dilation_rate\n",
    "padded_lvl = tf.pad(c1, [[0, 0],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [strided_search_range, strided_search_range],\n",
    "                         [0, 0]])\n",
    "_, h, w, c = c1.get_shape().as_list()\n",
    "c1_nchw = c1 #tf.transpose(c1, perm=[0, 3, 1, 2])\n",
    "pl_nchw = padded_lvl #tf.transpose(padded_lvl, perm=[0, 3, 1, 2])\n",
    "_, h_pad, w_pad, _ = pl_nchw.shape\n",
    "\n",
    "def patches_indices_meshgrid(image, patch_h, patch_w):\n",
    "    b, h, w, c = image.shape\n",
    "    indices=[list(tf.convert_to_tensor(tf.meshgrid(tf.range(b), tf.range(i, i + patch_h), tf.range(j, j + patch_w), tf.range(c)))) for i in range(0, h-patch_h+1) for j in range(0, w-patch_w+1)]\n",
    "    indices=tf.convert_to_tensor(indices)\n",
    "    # The indices are correct but we need to transpose to have the same order as extract_patches\n",
    "    indices = tf.transpose(indices, [0, 3, 2, 4, 5, 1])\n",
    "    indices = tf.reshape(indices, [indices.shape[0], -1, indices.shape[-1]])\n",
    "    return indices\n",
    "\n",
    "indices = patches_indices_meshgrid(pl_nchw, h, w)\n",
    "patches = tf.gather_nd(pl_nchw, indices, batch_dims=0)\n",
    "patches = tf.reshape(patches, [search_range*2+1, search_range*2+1, -1, h, w, c])\n",
    "patches = tf.transpose(patches, perm=[2, 0, 1, 3, 4, 5])\n",
    "\n",
    "c1_repeat = tf.expand_dims(c1,axis=1)\n",
    "c1_repeat = tf.expand_dims(c1_repeat,axis=1)\n",
    "c1_repeat = tf.tile(c1_repeat, [1,patches.shape[1], patches.shape[2],1, 1, 1])\n",
    "\n",
    "patches = c1_repeat*patches\n",
    "split_stack = tf.stack(tf.split(patches, num_or_size_splits=nbre_cuts, axis=-1), axis=-1)\n",
    "cost = tf.reduce_mean(split_stack, axis=-2)\n",
    "cost = tf.transpose(cost, perm=[0, 3, 4, 1, 2, 5])\n",
    "cost_vol2 = tf.reshape(cost, cost.shape[0:1] + cost.shape[1:3] + [cost.shape[3]*cost.shape[4]*cost.shape[5]])\n",
    "print(cost_vol2.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Ecris une fonction qui fait une"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
