{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_put_test_1_former (1, 24, 24, 1) (1, 24, 24, 1)\n",
      "---\n",
      "coords2d Tensor(\"PartitionedCall:0\", shape=(None, 24, 24, 3, 1), dtype=float32)\n",
      "prev_d Tensor(\"reshape/Reshape:0\", shape=(None, 576, 1, 1), dtype=float32)\n",
      "disp_test_1 (1, 24, 24, 1)\n",
      "out_put_test_1 (1, 24, 24, 1) (1, 24, 24, 1)\n",
      "tf.Tensor(\n",
      "[[ 2.005585]\n",
      " [91.437706]\n",
      " [ 5.253875]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 2.005585 ]\n",
      " [91.437706 ]\n",
      " [ 5.2538743]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "out_put_test_1_former (50, 24, 24, 1) (50, 24, 24, 1)\n",
      "---\n",
      "disp_test_1 (50, 24, 24, 1)\n",
      "out_put_test_1 (50, 24, 24, 1) (50, 24, 24, 1)\n",
      "tf.Tensor(\n",
      "[[0.53797257]\n",
      " [0.59596336]\n",
      " [0.33008036]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.53797257]\n",
      " [0.59596336]\n",
      " [0.33008036]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.depth_operations_functionnal import get_coords_2d, get_rot_mat, \\\n",
    "    repeat_const\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks, float32\n",
    "from keras import backend as K\n",
    "\n",
    "@tf.function\n",
    "def prev_d2disp_former(prev_d, rot, trans, camera):\n",
    "    \"\"\" Converts depth map corresponding to previous time step into the disparity map corresponding to current time step \"\"\"\n",
    "\n",
    "    with tf.compat.v1.name_scope(\"prev_d2disp\"):\n",
    "        b, h, w = prev_d.get_shape().as_list()[0:3]\n",
    "\n",
    "        coords2d, _ = get_coords_2d(prev_d, camera)\n",
    "\n",
    "        prev_d = tf.reshape(prev_d, [b, h * w, 1, 1])\n",
    "        coords2d = tf.reshape(coords2d, [b, h * w, 3, 1])\n",
    "        t = tf.reshape(trans, [b, 1, 3, 1])\n",
    "        f_vec = tf.reshape(tf.concat([camera[\"f\"], tf.ones([b, 1])], axis=1),\n",
    "                           [b, 1, 3, 1])\n",
    "\n",
    "        coords2d = coords2d * f_vec\n",
    "        scaled_t = t * f_vec\n",
    "\n",
    "        delta = (scaled_t - t[:, :, -1:, :] * coords2d) / (\n",
    "                    prev_d - t[:, :, -1:, :])\n",
    "\n",
    "        disp = tf.norm(delta[:, :, :2, :], axis=2)\n",
    "\n",
    "        return tf.stop_gradient(tf.reshape(disp, [b, h, w, 1]))\n",
    "\n",
    "def reshape_layer(tensor, shape, name=None):\n",
    "    tensor = ks.layers.Reshape(shape, name=name)(tensor)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def prev_d2disp(prev_d, rot, trans, camera):\n",
    "    \"\"\" Converts depth map corresponding to previous time step into the disparity map corresponding to current time step \"\"\"\n",
    "    b, h, w = prev_d.get_shape().as_list()[0:3]\n",
    "\n",
    "    coords2d, _ = get_coords_2d(prev_d, camera)\n",
    "    print(\"coords2d\", coords2d)\n",
    "    prev_d = reshape_layer(prev_d, [h * w, 1, 1,])\n",
    "    print(\"prev_d\", prev_d)\n",
    "    coords2d = reshape_layer(coords2d, [h * w, 3, 1,])\n",
    "\n",
    "    t = reshape_layer(trans, [1, 3, 1,])\n",
    "    myconst = tf.convert_to_tensor(np.ones((1, 1)).astype('float32'))\n",
    "    ones_ = tf.keras.layers.Lambda(lambda x: repeat_const(x, myconst))(camera[\"f\"])\n",
    "    f_vec = ks.layers.Concatenate(axis=1)([camera[\"f\"], ones_])\n",
    "    f_vec =  ks.layers.Reshape((1, 3, 1,),)(f_vec)\n",
    "\n",
    "    coords2d = coords2d * f_vec\n",
    "    scaled_t = t * f_vec\n",
    "\n",
    "    delta = (scaled_t - t[:, :, -1:, :] * coords2d) / (\n",
    "                prev_d - t[:, :, -1:, :])\n",
    "\n",
    "    disp = tf.norm(delta[:, :, :2, :], axis=2)\n",
    "    disp = reshape_layer(disp, [h, w, 1,])\n",
    "    disp = tf.stop_gradient(disp)\n",
    "    return disp\n",
    "\n",
    "disp = ks.Input(shape=(24, 24, 1,), dtype=float32)  # data image\n",
    "camera = {\"f\": ks.Input(shape=(2,), dtype=float32),\n",
    "          \"c\": ks.Input(shape=(2,), dtype=float32)}\n",
    "\n",
    "rot_input = ks.Input(shape=(4), dtype=float32,\n",
    "                     name=\"rot_input\")  # data camera displacement\n",
    "trans_input = ks.Input(shape=(3), dtype=float32,\n",
    "                       name=\"trans_input\")  # data camera displacement\n",
    "# output: TensorShape([1, 48, 48, 1])\n",
    "\n",
    "b=1\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "\n",
    "out_put_test_1_former = prev_d2disp_former(disp_test_1, rot_test_1, trans_test_1, camera_test_1)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former.shape, disp_test_1.shape)\n",
    "print(\"---\")\n",
    "\n",
    "depth_curr_l_function = lambda x: prev_d2disp(x[0], x[1], x[2], x[3])\n",
    "depth_curr_l = ks.layers.Lambda(depth_curr_l_function)((disp,rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[disp, camera, rot_input, trans_input],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "out_put_test_1 = model_full((disp_test_1, camera_test_1, rot_test_1, trans_test_1))\n",
    "\n",
    "print(\"disp_test_1\", disp_test_1.shape)\n",
    "print(\"out_put_test_1\", out_put_test_1.shape, disp_test_1.shape)\n",
    "\n",
    "print(out_put_test_1[0][0][0:3])\n",
    "print(out_put_test_1_former[0][0][0:3])\n",
    "print()\n",
    "\n",
    "\n",
    "b=50\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "\n",
    "out_put_test_1_former = prev_d2disp_former(disp_test_1, rot_test_1, trans_test_1, camera_test_1)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former.shape, disp_test_1.shape)\n",
    "print(\"---\")\n",
    "\n",
    "depth_curr_l_function = lambda x: prev_d2disp(x[0], x[1], x[2], x[3])\n",
    "depth_curr_l = ks.layers.Lambda(depth_curr_l_function)((disp,rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[disp, camera, rot_input, trans_input],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "out_put_test_1 = model_full((disp_test_1, camera_test_1, rot_test_1, trans_test_1))\n",
    "\n",
    "print(\"disp_test_1\", disp_test_1.shape)\n",
    "print(\"out_put_test_1\", out_put_test_1.shape, disp_test_1.shape)\n",
    "\n",
    "print(out_put_test_1[0][0][0:3])\n",
    "print(out_put_test_1_former[0][0][0:3])\n",
    "print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}