{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbre_copies 9\n",
      "range_before_reshape (9,)\n",
      "expl_range (1, 9, 1, 1, 1)\n",
      "disp_tile (None, 9, 48, 48, 1)\n",
      "disp_reshape (None, 9, 48, 48, 1)\n",
      "expl_range (1, 9, 1, 1, 1)\n",
      "disp_sum=disp_sum_reshape=disp_reshape (None, 9, 48, 48, 1)\n",
      "disp_clip (None, 9, 48, 48, 1)\n",
      "coords2d (None, 48, 48, 3, 1)\n",
      "coords2d reshape (None, 2304, 3, 1)\n",
      "Tensor(\"Reshape_2:0\", shape=(None, 3, 3), dtype=float32)\n",
      "rot mat Tensor(\"reshape_1/Reshape:0\", shape=(None, 1, 3, 3), dtype=float32)\n",
      "Tensor(\"trans:0\", shape=(None, 3), dtype=float32)\n",
      "ok\n",
      "proj_coords (None, 1, 48, 48, 2)\n",
      "disp_to_flow (None, 9, 48, 48, 1)\n",
      "flow2 (None, 9, 48, 48, 2)\n",
      "c1 (None, 9, 48, 48, 64)\n",
      "combined_data (None, 9, 48, 48, 65)\n",
      "functionnal\n",
      "(1, 48, 48, 2)\n",
      "(None, 9, 48, 48, 2)\n",
      "image (None, 9, 48, 48, 65)\n",
      "query_points_flattened (None, 9, 2304, 2)\n",
      "num_queries Tensor(\"dense_image_warp/interpolate_bilinear/strided_slice_5:0\", shape=(), dtype=int32) unstacked_query_points 2\n",
      "batch_offsets (None, 9, 1)\n",
      "flattened_grid (None, 20736, 65)\n",
      "floors (None, 9, 2304)\n",
      "linear_coordinates (None, 9, 2304)\n",
      "flattened_grid (None, 20736, 65)\n",
      "gathered_values (None, 9, 2304, 65)\n",
      "top_left (None, 9, 2304, 65)\n",
      "linear_coordinates (None, 9, 2304)\n",
      "flattened_grid (None, 20736, 65)\n",
      "gathered_values (None, 9, 2304, 65)\n",
      "linear_coordinates (None, 9, 2304)\n",
      "flattened_grid (None, 20736, 65)\n",
      "gathered_values (None, 9, 2304, 65)\n",
      "linear_coordinates (None, 9, 2304)\n",
      "flattened_grid (None, 20736, 65)\n",
      "gathered_values (None, 9, 2304, 65)\n",
      "bottom_right (None, 9, 2304, 65)\n",
      "combined_data_w (None, 9, 48, 48, 65)\n",
      "c2_w (None, 9, 48, 48, 64)\n",
      "prev_disp (None, 9, 48, 48)\n",
      "mult (None, 9, 48, 48, 64)\n",
      "split [<tf.Tensor 'split:0' shape=(None, 9, 48, 48, 32) dtype=float16>, <tf.Tensor 'split:1' shape=(None, 9, 48, 48, 32) dtype=float16>]\n",
      "sub_costs (None, 2, 9, 48, 48, 32)\n",
      "cv (None, 2, 9, 48, 48)\n",
      "cv_to_cast (None, 18, 48, 48)\n",
      "cv_cast (None, 48, 48, 18)\n",
      "prev_disp (None, 9, 48, 48)\n",
      "prev_disp_transposed (None, 48, 48, 9)\n",
      "\n",
      "---\n",
      "out_put_test_1_former (5, 48, 48, 18) (5, 48, 48, 9)\n",
      "---\n",
      "get_disparity_sweeping_cv_former_intermediate (5, 48, 48, 18) (5, 48, 48, 9)\n",
      "---\n",
      "get_disparity_sweeping_cv (5, 48, 48, 18) (5, 48, 48, 9)\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "(5, 48, 48, 18) (5, 48, 48, 18) (5, 48, 48, 18)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.dense_image_warp_functionnal import dense_image_warp_intermediate\n",
    "from utils.depth_operations_functionnal import \\\n",
    "    get_disparity_sweeping_cv_former_intermediate, \\\n",
    "    get_disparity_sweeping_cv_former, tile_not_in_batch, get_coords_2d, \\\n",
    "    get_rot_mat, repeat_const\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks, float32\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_disparity_sweeping_cv(c1, c2, disp_prev_t, disp, rot, trans, camera,\n",
    "                              search_range, nbre_cuts=1):\n",
    "    \"\"\" Computes the DSCV as presented in the paper \"\"\"\n",
    "\n",
    "    # Prepare inputs\n",
    "    nbre_copies = 2 * search_range + 1\n",
    "    print(\"nbre_copies\",nbre_copies)\n",
    "    range_before_reshape = tf.range(-search_range, search_range + 1, 1.0, dtype=tf.float32)\n",
    "    print(\"range_before_reshape\", range_before_reshape.shape)\n",
    "    expl_range = tf.reshape(range_before_reshape , [1, -1, 1, 1, 1])\n",
    "    print(\"expl_range\", expl_range.shape)\n",
    "    b, h, w = c1.get_shape().as_list()[0:3]\n",
    "\n",
    "    disp = tile_not_in_batch(disp, nbre_copies)\n",
    "    print(\"disp_tile\", disp.shape)\n",
    "    disp = tf.reshape(disp, [-1, nbre_copies, w, h, 1])\n",
    "    print(\"disp_reshape\", disp.shape)\n",
    "\n",
    "    print(\"expl_range\", expl_range.shape)\n",
    "    disp = disp + expl_range\n",
    "    print(\"disp_sum=disp_sum_reshape=disp_reshape\", disp.shape)\n",
    "    disp = tf.clip_by_value(disp, 1e-6, 1e6)\n",
    "    print(\"disp_clip\", disp.shape)\n",
    "    # Compute disp independent factors\n",
    "    coords2d, _ = get_coords_2d(c1, camera)\n",
    "    print(\"coords2d\", coords2d.shape)\n",
    "    coords2d = ks.layers.Reshape([h * w, 3, 1,])(coords2d)\n",
    "    print(\"coords2d reshape\", coords2d.shape)\n",
    "    # rot_mat = tf.expand_dims(get_rot_mat(rot), axis=1)\n",
    "    rot_mat = get_rot_mat(rot)\n",
    "    print(rot_mat)\n",
    "    rot_mat = ks.layers.Reshape((1, rot_mat.shape[1], rot_mat.shape[2],), )(rot_mat)\n",
    "    print(\"rot mat\", rot_mat)\n",
    "    print(trans)\n",
    "    t = ks.layers.Reshape((1, 3, 1, ), )(trans)\n",
    "\n",
    "    myconst = tf.convert_to_tensor(np.ones((1, 1)).astype('float32'))\n",
    "    ones_ = tf.keras.layers.Lambda(lambda x: repeat_const(x, myconst))(camera[\"f\"])\n",
    "    f_vec = ks.layers.Concatenate(axis=1)([camera[\"f\"], ones_])\n",
    "    f_vec =  ks.layers.Reshape((1, 3, 1,),)(f_vec)\n",
    "\n",
    "    rot_coords = rot_mat @ coords2d\n",
    "    alpha = rot_coords[:, :, -1:, :]\n",
    "    proj_coords = rot_coords * f_vec / alpha\n",
    "    scaled_t = t * f_vec\n",
    "    print(\"ok\")\n",
    "    delta_x = scaled_t[:, :, 0, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                            :, 0, 0]\n",
    "    delta_y = scaled_t[:, :, 1, 0] - scaled_t[:, :, 2, 0] * proj_coords[:,\n",
    "                                                            :, 1, 0]\n",
    "    delta_x = ks.layers.Reshape([1, h, w, 1,],)(delta_x)\n",
    "    delta_y = ks.layers.Reshape([1, h, w, 1,],)(delta_y)\n",
    "\n",
    "    start_coords = ks.layers.Reshape([ 1, h, w, 2,],)(coords2d[:, :, :2, :] * f_vec[:, :, :2, :])\n",
    "    proj_coords = ks.layers.Reshape([1, h, w, 2,],)(proj_coords[:, :, :2, :])\n",
    "    print(\"proj_coords\", proj_coords.shape)\n",
    "\n",
    "    # disp to flow\n",
    "    print(\"disp_to_flow\", disp.shape)\n",
    "    sqrt_value = tf.sqrt(delta_x ** 2 + delta_y ** 2)\n",
    "    divider = sqrt_value / disp  # is correct computation after simplification\n",
    "\n",
    "    delta = tf.concat([delta_x / divider, delta_y / divider], axis=-1)\n",
    "    flow = proj_coords + delta - start_coords\n",
    "    flow = tf.reverse(flow, axis=[-1])\n",
    "\n",
    "    c1 = tile_not_in_batch(c1, nbre_copies)\n",
    "    combined_data = tile_not_in_batch(tf.concat([c2, disp_prev_t], axis=-1),\n",
    "                                  nbre_copies)\n",
    "\n",
    "    print(\"flow2\", flow.shape)\n",
    "    print(\"c1\", c1.shape)\n",
    "    print(\"combined_data\", combined_data.shape)\n",
    "\n",
    "    combined_data_w = dense_image_warp_intermediate(combined_data, flow)\n",
    "    # combined_data_w = combined_data\n",
    "\n",
    "    print(\"combined_data_w\", combined_data_w.shape)\n",
    "    c2_w = combined_data_w[..., :-1]\n",
    "    prev_disp = combined_data_w[..., -1]\n",
    "    print(\"c2_w\", c2_w.shape)\n",
    "    print(\"prev_disp\", prev_disp.shape)\n",
    "    # Compute costs (operations performed in float16 for speedup)\n",
    "    mult = tf.cast(c1, tf.float16) * tf.cast(c2_w, tf.float16)\n",
    "    print(\"mult\", mult.shape)\n",
    "    split = tf.split(mult, num_or_size_splits=nbre_cuts, axis=-1)\n",
    "    print(\"split\", split)\n",
    "    sub_costs = tf.stack(split, 1)\n",
    "    print(\"sub_costs\", sub_costs.shape)\n",
    "    cv = tf.reduce_mean(sub_costs, axis=-1)\n",
    "    print(\"cv\", cv.shape)\n",
    "    cv_to_cast = tf.reshape(cv, [-1, (nbre_cuts) * nbre_copies, h, w])\n",
    "    print(\"cv_to_cast\", cv_to_cast.shape)\n",
    "\n",
    "    # cv_to_cast (18, 5, 48, 48)\n",
    "    # cv_cast (5, 48, 48, 18)\n",
    "\n",
    "    cv = tf.cast(tf.transpose(cv_to_cast, perm=[0, 2, 3, 1]), tf.float32)\n",
    "    print(\"cv_cast\", cv.shape)\n",
    "    print(\"prev_disp\", prev_disp.shape)\n",
    "    tmp = prev_disp\n",
    "    prev_disp = tf.transpose(prev_disp , perm=[0, 2, 3, 1])\n",
    "    print(\"prev_disp_transposed\", prev_disp.shape)\n",
    "    return cv, prev_disp\n",
    "\n",
    "h= 48\n",
    "w = 48\n",
    "\n",
    "c1 = ks.Input(shape=(h,w, 64,), dtype=float32)  # data image\n",
    "c2 = ks.Input(shape=(h,w, 64,), dtype=float32)  # data image\n",
    "disp_prev_t = ks.Input(shape=(h,w, 1,), dtype=float32)  # data image\n",
    "disp = ks.Input(shape=(h,w, 1,), dtype=float32)  # data image\n",
    "camera = {\"f\": ks.Input(shape=(2,), dtype=float32),\n",
    "          \"c\": ks.Input(shape=(2,), dtype=float32)}\n",
    "\n",
    "rot_input = ks.Input(shape=(4), dtype=float32,\n",
    "                     name=\"rot_input\")  # data camera displacement\n",
    "trans_input = ks.Input(shape=(3), dtype=float32,\n",
    "                       name=\"trans_input\")  # data camera displacement\n",
    "search_range=4\n",
    "nbre_cuts=2\n",
    "\n",
    "get_disparity_sweeping_cv_function = lambda x: get_disparity_sweeping_cv(x[0], x[1], x[2], x[3], x[4], x[5], x[6], search_range, nbre_cuts)\n",
    "depth_curr_l = ks.layers.Lambda(get_disparity_sweeping_cv_function)((c1, c2,disp_prev_t, disp, rot_input, trans_input,camera))\n",
    "\n",
    "model_full = ks.Model(inputs=[c1, c2,disp_prev_t, disp, rot_input, trans_input,camera],\n",
    "                      outputs=depth_curr_l)\n",
    "\n",
    "#get_disparity_sweeping_cv_output (TensorShape([1, 48, 48, 18]), TensorShape([1, 48, 48, 9]))\n",
    "b=5\n",
    "c1_test_1 = tf.random.uniform([b] + c1.shape[1:])\n",
    "c2_test_1 = tf.random.uniform([b] + c2.shape[1:])\n",
    "disp_prev_t_test_1 = tf.random.uniform([b] + disp_prev_t.shape[1:])\n",
    "disp_test_1 = tf.random.uniform([b] + disp.shape[1:])\n",
    "camera_test_1 = {\"f\":  tf.random.uniform([b] + camera[\"f\"].shape[1:]),\n",
    "          \"c\":  tf.random.uniform([b] + camera[\"c\"].shape[1:])}\n",
    "rot_test_1 = tf.random.uniform([b] + rot_input.shape[1:])\n",
    "trans_test_1 = tf.random.uniform([b] + trans_input.shape[1:])\n",
    "print()\n",
    "print(\"---\")\n",
    "out_put_test_1_former = get_disparity_sweeping_cv_former(c1_test_1, c2_test_1, disp_prev_t_test_1, disp_test_1, rot_test_1, trans_test_1, camera_test_1, search_range, nbre_cuts=nbre_cuts)\n",
    "print(\"out_put_test_1_former\", out_put_test_1_former[0].shape, out_put_test_1_former[1].shape)\n",
    "print(\"---\")\n",
    "\n",
    "out_put_test_1_former_intermediate = get_disparity_sweeping_cv_former_intermediate(c1_test_1, c2_test_1, disp_prev_t_test_1, disp_test_1, rot_test_1, trans_test_1, camera_test_1, search_range, nbre_cuts=nbre_cuts)\n",
    "print(\"get_disparity_sweeping_cv_former_intermediate\", out_put_test_1_former_intermediate[0].shape, out_put_test_1_former_intermediate[1].shape)\n",
    "print(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "out_put_test_1 = model_full((c1_test_1, c2_test_1, disp_prev_t_test_1, disp_test_1, rot_test_1, trans_test_1, camera_test_1))\n",
    "print(\"get_disparity_sweeping_cv\", out_put_test_1[0].shape, out_put_test_1[1].shape)\n",
    "print(\"---\")\n",
    "\n",
    "# print(out_put_test_1_former[2][-1][0][0])\n",
    "# print(out_put_test_1_former_intermediate[2][-1][0][0])\n",
    "# print(tf.reduce_all(tf.math.equal(out_put_test_1_former_intermediate[2][0], out_put_test_1_former[2][0])))\n",
    "print(\"---\")\n",
    "print(\"---\")\n",
    "print(\"---\")\n",
    "tensor1 = out_put_test_1_former[0]\n",
    "tensor2 = out_put_test_1_former_intermediate[0]\n",
    "tensor3 = out_put_test_1[0]\n",
    "print(tensor1.shape, tensor2.shape,tensor3.shape)\n",
    "# print(tensor1)\n",
    "# print(tensor2)\n",
    "\n",
    "print(tf.reduce_all(tf.math.equal(out_put_test_1_former_intermediate[0], out_put_test_1_former[0])))\n",
    "print(tf.reduce_all(tf.math.equal(out_put_test_1_former_intermediate[0], out_put_test_1[0])))\n",
    "print(tf.reduce_all(tf.math.equal(out_put_test_1_former_intermediate[1], out_put_test_1_former[1])))\n",
    "print(tf.reduce_all(tf.math.equal(out_put_test_1_former_intermediate[1], out_put_test_1[1])))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}